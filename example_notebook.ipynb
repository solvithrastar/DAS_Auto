{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake Detections using Computer Vision\n",
    "\n",
    "This is a little notebook created to demonstrate how the presented algorithm works. The notebook has access to four images which it will use to showcase the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_processing as ip\n",
    "import pipeline\n",
    "import os, pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step Processing\n",
    "\n",
    "First, we'll go through the process step by step and see the results.\n",
    "\n",
    "Let's first take a look at the four images that we have as examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images in as RGBA images\n",
    "\n",
    "image_names = os.listdir(\"example_images\")\n",
    "image_paths = []\n",
    "for image in image_names:\n",
    "    image_paths.append(\"example_images\" / pathlib.Path(image))\n",
    "\n",
    "images = []\n",
    "for image in image_paths:\n",
    "    images.append(ip.read_image_from_file(image, as_gray=False))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, dpi=300)\n",
    "\n",
    "axes = axes.flatten()\n",
    "x_range = (50, 1750)\n",
    "y_range = (130, 1100)\n",
    "\n",
    "for _i, ax in enumerate(axes):\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(image_names[_i], fontsize=6)\n",
    "    \n",
    "    ax.imshow(images[_i], cmap=\"seismic\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a variety of different signals here.\n",
    "\n",
    "Now let's read these images and convert them to grayscale to prepare them for the algorithm. To increase visibility, we will invert the colorscale, the algorithm is working on the normal colorscale though. This should reproduce the figures from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image in image_paths:\n",
    "    images.append(ip.read_image_from_file(image, as_gray=True))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "x_range = (50, 1750)\n",
    "y_range = (130, 1100)\n",
    "\n",
    "for _i, ax in enumerate(axes):\n",
    "    images[_i] = ip.crop_image(images[_i], x_range=x_range, y_range=y_range)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(image_names[_i], fontsize=6)\n",
    "    img = ax.imshow(images[_i])\n",
    "    img.set_cmap('gray_r')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now read in the images in grayscale and we can start processing them. The first thing we'll do is to reduce the noise level by removing the median brightness per channel. Remember that the colorscale is inverted so in this case it will look like removing the median darkness per channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for _i, ax in enumerate(axes):\n",
    "    images[_i] = ip.remove_median_brightness(images[_i])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(image_names[_i], fontsize=6)\n",
    "    img = ax.imshow(images[_i])\n",
    "    img.set_cmap('gray_r')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use Otsu's method to define a brightness threshold deciding what is \"foreground\" and what is \"background\", we can thus create a binary image.\n",
    "\n",
    "A good explanation of how Otsu's method works can be found [here](https://www.youtube.com/watch?v=jUUkMaNuHP8&)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for _i, ax in enumerate(axes):\n",
    "    thresholds = ip.compute_brightness_thresholds(images[_i], classes=4)\n",
    "    images[_i] = ip.apply_brightness_threshold(images[_i], threshold=thresholds[0])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(image_names[_i], fontsize=6)\n",
    "    img = ax.imshow(images[_i])\n",
    "    img.set_cmap('gray_r')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we are actually starting to see some things quite clearly. If we look closely, we can find three earthquakes in these four pictures. The obvious one is in the top right, but there is a small one in the top left too and a very small one in the bottom left of the picture on the bottom right.\n",
    "\n",
    "We can see how the coherency of the signals from the earthquakes is much higher than the rest of the signals. We can use this information when we apply the coherency threshold in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for _i, ax in enumerate(axes):\n",
    "    images[_i] = ip.coherency_thresholding(images[_i], min_cluster_size=64)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(image_names[_i], fontsize=6)\n",
    "    img = ax.imshow(images[_i])\n",
    "    img.set_cmap('gray_r')\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes quite a difference as you can see. We have gotten rid of a lot of noisy signal while keeping signal from all three earthquakes in there. You can also notice now that all the signal in there is contained in small horizontal lines. We can thus try creating a template which looks a bit like that and remove those lines from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# It can make things more intuitive to relate the temple size with the size of \n",
    "# the actual images\n",
    "cols = images[0].shape[1]\n",
    "# It needs to be of an integer size so we use floor division\n",
    "template = ip.create_shaped_template(vertical_length=1, horizontal_length=cols // 200)\n",
    "\n",
    "for _i, ax in enumerate(axes):\n",
    "    images[_i] = ip.remove_template_shape(images[_i].astype(np.float32), template=template)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(image_names[_i], fontsize=6)\n",
    "    img = ax.imshow(images[_i])\n",
    "    img.set_cmap('gray_r')\n",
    "plt.tight_layout()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the image is cleaner than before but not fully clean.\n",
    "Those horizontal lines are much less coherent though, so we can apply the coherency threshold again and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for _i, ax in enumerate(axes):\n",
    "    images[_i] = ip.coherency_thresholding(images[_i], min_cluster_size=64)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_title(image_names[_i], fontsize=6)\n",
    "    img = ax.imshow(images[_i])\n",
    "    img.set_cmap('gray_r')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have left are the signals from the Earthquakes. We can count the True signals in each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_props = []\n",
    "for i in range(len(images)):\n",
    "    reg_props.append(ip.get_regionprops(images[i]))\n",
    "    print(f\"Image: {image_names[i]} has {len(reg_props[i])} True regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which checks out to what we estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All at once\n",
    "\n",
    "We can do all of this without all the plotting, and just get a quick answer from the image. This can be done with either a data file or an image.\n",
    "\n",
    "We do not provide a data reader as data readers can contain proprietary information, so here we will only demonstrate the pipeline using images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _i, image in enumerate(image_paths):\n",
    "    quake = pipeline.earthquake_in_image(\n",
    "        filename = image,\n",
    "        x_range = (50, 1750),\n",
    "        y_range = (130, 1100),\n",
    "        median=True,\n",
    "        mean=False,\n",
    "        classes=4,\n",
    "        threshold=0,\n",
    "        min_cluster_size=64,\n",
    "        templates=(1, 1700 // 200)\n",
    "    )\n",
    "    if quake:\n",
    "        print(f\"Image {image_names[_i]} includes an earthquake\")\n",
    "    else:\n",
    "        print(f\"Image {image_names[_i]} does not include an earthquake\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the same answer as we got from the step-by-step showcase."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e6d14024b60bd2194f6b1a124a4a53e64caf028cef36d55aadf4932dd40258e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
